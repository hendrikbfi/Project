{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "from prophet.serialize import model_to_json, model_from_json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandasql import sqldf\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import mysql.connector as mysql_drive\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "# Set Pandas options to display more columns\n",
    "pd.options.display.max_columns=150\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#Weighted Mean Absolute Percentage Error\n",
    "def wape(y_true, y_pred):\n",
    "    return np.abs(y_true - y_pred).sum() / np.abs(y_true).sum()\n",
    "def wbpe(y_true, y_pred):\n",
    "    return (y_true - y_pred).sum() / np.abs(y_true).sum()\n",
    "def wcpe(wape, wbpe, beta):\n",
    "    a = 1 - np.clip(wape, a_min = 0, a_max = 1)\n",
    "    b = 1 - min(1, np.abs(wbpe))\n",
    "    return ((1 + beta**2) * a * b) / (beta**2 * a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#days_ago_60 = str((datetime.now() - timedelta(60) - timedelta(35)).date()) # - timedelta(21) bisa diubah agar jadi '2023-05-31'\n",
    "#days_ago_37 = str((datetime.now() - timedelta(44) - timedelta(35)).date())\n",
    "#days_ago_30 = str((datetime.now() - timedelta(30) - timedelta(35)).date())\n",
    "#days_ago_14 = str((datetime.now() - timedelta(14) - timedelta(35)).date())\n",
    "#days_ago_1 = str((datetime.now() - timedelta(1)   - timedelta(35)).date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Database date  :  ('2023-07-27',)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    mydb = mysql_drive.connect(host=os.getenv(\"HOST\"), user=os.getenv(\"DATABASE_USER\"),port=os.getenv(\"DATABASE_PORT\"),\n",
    "                                database=os.getenv(\"DATABASE_NAME\"), password=os.getenv(\"DATABASE_PASSWORD\"))\n",
    "    mycursor = mydb.cursor()\n",
    "    mycursor.execute('''select max(date_format(sk_created_date,'%Y-%m-%d')) as last_date\n",
    "    from digital_leads.digital_leads''')\n",
    "    last_date = mycursor.fetchone()\n",
    "except Exception as e:\n",
    "    mydb.close()\n",
    "    print(str(e))\n",
    "print(\"Last Database date  : \" , last_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "days_ago_14 :  2023-07-14\n",
      "days_ago_30 :  2023-06-28\n",
      "days_ago_44 :  2023-06-14\n",
      "days_ago_60 :  2023-05-29\n"
     ]
    }
   ],
   "source": [
    "days_ago_1_str  = ''.join(last_date)\n",
    "days_ago_1 = datetime.strptime(days_ago_1_str, '%Y-%m-%d').date()\n",
    "days_ago_14 = days_ago_1 - timedelta(days = 13)\n",
    "days_ago_30 = days_ago_1 - timedelta(days = 29)\n",
    "days_ago_44 = days_ago_1 - timedelta(days = 43)\n",
    "days_ago_60 = days_ago_1 - timedelta(days = 59)\n",
    "\n",
    "print(\"days_ago_14 : \" , days_ago_14)\n",
    "print(\"days_ago_30 : \" , days_ago_30)\n",
    "print(\"days_ago_44 : \" , days_ago_44)\n",
    "print(\"days_ago_60 : \" , days_ago_60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    mydb = mysql_drive.connect(host=os.getenv(\"HOST\"), user=os.getenv(\"DATABASE_USER\"),port=os.getenv(\"DATABASE_PORT\"),\n",
    "                                database=os.getenv(\"DATABASE_NAME\"), password=os.getenv(\"DATABASE_PASSWORD\"))\n",
    "    query = '''\n",
    "with google As (\n",
    "Select date_format(created_date,'%Y-%m-%d') as created_date,\n",
    "\tCASE WHEN lower(googleAdsCampaignName) LIKE '%mobil%' THEN 'BPKB Mobil'\n",
    "\t\t WHEN lower(googleAdsCampaignName) LIKE '%motor%' THEN 'BPKB Motor'\n",
    "\t\t WHEN lower(googleAdsCampaignName) LIKE '%rumah%' THEN 'Sertifikat Rumah'\n",
    "\t\t WHEN lower(googleAdsCampaignName) LIKE '%all product%' THEN 'All Product'\n",
    "\t\t WHEN lower(googleAdsCampaignName) LIKE '%all-product%' THEN 'All Product'\n",
    "\t\t else 'Others'\n",
    "\t\t END AS product,\n",
    "\t\tgoogleAdsCampaignName as campaign, \n",
    "\t\tsum(advertiserAdClicks) as clicks, sum(advertiserAdCost) as cost\n",
    "\tfrom digital_leads.google_ads_metrics\n",
    "\twhere googleAdsCampaignName <> '(not set)'\n",
    "\t\t\tand date_format(created_date,'%Y-%m-%d') <= '{0}'\n",
    "\tgroup by created_date, googleAdsCampaignName, product\n",
    "),\n",
    "leads As (\n",
    "select utm_original, product, date_format(sk_created_date,'%Y-%m-%d') as leads_date, sum(funnel_leads) as leads\n",
    "    from digital_leads.digital_leads\n",
    "    where submissionid is not null and group_utm_source = 'Google'\n",
    "          and product in ('BPKB Mobil', 'BPKB Motor', 'Sertifikat Rumah')\n",
    "          and sk_created_date > 1 and utm_original is not null\n",
    "    group by utm_original, product, sk_created_date\n",
    "),\n",
    "prospect As (\n",
    "select utm_original, product, date_format(sk_closing_date,'%Y-%m-%d') as prospect_date, sum(funnel_prospect) as prospect\n",
    "       from digital_leads.digital_leads\n",
    "       where submissionid is not null and group_utm_source = 'Google'\n",
    "             and product in ('BPKB Mobil', 'BPKB Motor', 'Sertifikat Rumah')\n",
    "             and sk_closing_date > 1 and utm_original is not null\n",
    "       group by utm_original, product, sk_closing_date                \n",
    "),\n",
    "funding As (\n",
    "select utm_original, product, date_format(sk_golive_date,'%Y-%m-%d') as funding_date, sum(funnel_funding) as funding,\n",
    "\t\tsum(case when funnel_funding = 1 then fundingamount  else 0 end) as NTF\n",
    "       from digital_leads.digital_leads\n",
    "       where submissionid is not null and group_utm_source = 'Google'\n",
    "             and product in ('BPKB Mobil', 'BPKB Motor', 'Sertifikat Rumah')\n",
    "             and sk_golive_date > 1 and utm_original is not null\n",
    "       group by utm_original, product, sk_golive_date\n",
    "),\n",
    "g_l As (\n",
    "select g.created_date, g.product, g.campaign, g.clicks, g.cost, l.leads\n",
    "\tfrom google as g\n",
    "\tleft outer join leads as l on g.created_date = l.leads_date\n",
    "\t\t\t\t\t\tand g.campaign = l.utm_original\n",
    "\t\t\t\t\t\tand g.product = l.product\n",
    "\twhere g.product not in ('All Product', 'Others')\n",
    "union \n",
    "select l.leads_date as created_date, l.product, l.utm_original as campaign, g.clicks, g.cost, l.leads\n",
    "\tfrom google as g\n",
    "\tright outer join leads as l on g.created_date = l.leads_date\n",
    "\t\t\t\t\t\tand g.campaign = l.utm_original\n",
    "\t\t\t\t\t\tand g.product = l.product\n",
    "\twhere g.product not in ('All Product', 'Others')\n",
    ")\n",
    ",\n",
    "g_lp As (\n",
    "select gl.created_date, gl.product, gl.campaign, gl.clicks, gl.cost, gl.leads, p.prospect\n",
    "\tfrom g_l as gl\n",
    "\tleft outer join prospect as p on gl.created_date = p.prospect_date\n",
    "\t\t\t\t\t\tand gl.campaign = p.utm_original\n",
    "\t\t\t\t\t\tand gl.product = p.product\n",
    "union \n",
    "select p.prospect_date as created_date, p.product, p.utm_original as campaign, gl.clicks, gl.cost, gl.leads, p.prospect\n",
    "\tfrom g_l as gl\n",
    "\tright outer join prospect as p on gl.created_date = p.prospect_date\n",
    "\t\t\t\t\t\tand gl.campaign = p.utm_original\n",
    "\t\t\t\t\t\tand gl.product = p.product\n",
    ")\n",
    "select glp.created_date, glp.product, glp.campaign, glp.clicks, glp.cost, glp.leads, glp.prospect, f.funding, f.NTF\n",
    "\tfrom g_lp as glp\n",
    "\tleft outer join funding as f on glp.created_date = f.funding_date\n",
    "\t\t\t\t\t\tand glp.campaign = f.utm_original\n",
    "\t\t\t\t\t\tand glp.product = f.product\n",
    "union \n",
    "select f.funding_date as created_date, f.product, f.utm_original as campaign, glp.clicks, glp.cost, glp.leads, glp.prospect,\n",
    "\t\tf.funding, f.NTF\n",
    "\tfrom g_lp as glp\n",
    "\tright outer join funding as f on glp.created_date = f.funding_date\n",
    "\t\t\t\t\t\tand glp.campaign = f.utm_original\n",
    "\t\t\t\t\t\tand glp.product = f.product;     \n",
    "    '''.format(days_ago_1)\n",
    "    google = pd.read_sql(query,mydb)\n",
    "    mydb.close() #close the connection\n",
    "except Exception as e:\n",
    "    mydb.close()\n",
    "    print(str(e))\n",
    "#google.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>campaign</th>\n",
       "      <th>product</th>\n",
       "      <th>count_train</th>\n",
       "      <th>count_valid</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Leads | BPKB Mobil | Discovery | Web 1 | Natio...</td>\n",
       "      <td>BPKB Mobil</td>\n",
       "      <td>63</td>\n",
       "      <td>26</td>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>2023-07-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Leads | BPKB Mobil | Search | Web 1 | Jabarteng</td>\n",
       "      <td>BPKB Mobil</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>2023-06-06</td>\n",
       "      <td>2023-07-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Leads | BPKB Mobil | Search | Web 1 | Jabodeta...</td>\n",
       "      <td>BPKB Mobil</td>\n",
       "      <td>18</td>\n",
       "      <td>30</td>\n",
       "      <td>2023-05-17</td>\n",
       "      <td>2023-07-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Leads | BPKB Mobil | Search | Web 1 | Nationwi...</td>\n",
       "      <td>BPKB Mobil</td>\n",
       "      <td>119</td>\n",
       "      <td>30</td>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>2023-07-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Leads | BPKB Motor | Discovery | Web 1 | Natio...</td>\n",
       "      <td>BPKB Motor</td>\n",
       "      <td>58</td>\n",
       "      <td>8</td>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>2023-07-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Leads | BPKB Motor | Search | Web 1 | Jabarteng</td>\n",
       "      <td>BPKB Motor</td>\n",
       "      <td>22</td>\n",
       "      <td>28</td>\n",
       "      <td>2023-06-05</td>\n",
       "      <td>2023-07-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Leads | BPKB Motor | Search | Web 1 | Jabodetabek</td>\n",
       "      <td>BPKB Motor</td>\n",
       "      <td>24</td>\n",
       "      <td>29</td>\n",
       "      <td>2023-06-05</td>\n",
       "      <td>2023-07-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Leads | BPKB Motor | Search | Web 1 | Nationwi...</td>\n",
       "      <td>BPKB Motor</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>2023-07-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Leads | Rumah | Search | Web 1 | Jabodetabek</td>\n",
       "      <td>Sertifikat Rumah</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>2023-06-05</td>\n",
       "      <td>2023-07-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Leads | Seritifikat Rumah | Discovery | Web 1 ...</td>\n",
       "      <td>Sertifikat Rumah</td>\n",
       "      <td>60</td>\n",
       "      <td>15</td>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>2023-07-27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            campaign           product  \\\n",
       "0  Leads | BPKB Mobil | Discovery | Web 1 | Natio...        BPKB Mobil   \n",
       "1    Leads | BPKB Mobil | Search | Web 1 | Jabarteng        BPKB Mobil   \n",
       "2  Leads | BPKB Mobil | Search | Web 1 | Jabodeta...        BPKB Mobil   \n",
       "3  Leads | BPKB Mobil | Search | Web 1 | Nationwi...        BPKB Mobil   \n",
       "4  Leads | BPKB Motor | Discovery | Web 1 | Natio...        BPKB Motor   \n",
       "5    Leads | BPKB Motor | Search | Web 1 | Jabarteng        BPKB Motor   \n",
       "6  Leads | BPKB Motor | Search | Web 1 | Jabodetabek        BPKB Motor   \n",
       "7  Leads | BPKB Motor | Search | Web 1 | Nationwi...        BPKB Motor   \n",
       "8       Leads | Rumah | Search | Web 1 | Jabodetabek  Sertifikat Rumah   \n",
       "9  Leads | Seritifikat Rumah | Discovery | Web 1 ...  Sertifikat Rumah   \n",
       "\n",
       "   count_train  count_valid         min         max  \n",
       "0           63           26  2023-02-01  2023-07-27  \n",
       "1           10           29  2023-06-06  2023-07-27  \n",
       "2           18           30  2023-05-17  2023-07-27  \n",
       "3          119           30  2023-02-01  2023-07-27  \n",
       "4           58            8  2023-02-01  2023-07-27  \n",
       "5           22           28  2023-06-05  2023-07-27  \n",
       "6           24           29  2023-06-05  2023-07-27  \n",
       "7           20            4  2023-05-01  2023-07-20  \n",
       "8           24           30  2023-06-05  2023-07-27  \n",
       "9           60           15  2023-02-01  2023-07-27  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    mydb = mysql_drive.connect(host=os.getenv(\"HOST\"), user=os.getenv(\"DATABASE_USER\"),port=os.getenv(\"DATABASE_PORT\"),\n",
    "                                database=os.getenv(\"DATABASE_NAME\"), password=os.getenv(\"DATABASE_PASSWORD\"))\n",
    "    query = '''\n",
    "        select googleAdsCampaignName as campaign,\n",
    "            CASE WHEN lower(googleAdsCampaignName) LIKE '%mobil%' THEN 'BPKB Mobil'\n",
    "\t\t        WHEN lower(googleAdsCampaignName) LIKE '%motor%' THEN 'BPKB Motor'\n",
    "\t\t        WHEN lower(googleAdsCampaignName) LIKE '%rumah%' THEN 'Sertifikat Rumah'\n",
    "\t\t        WHEN lower(googleAdsCampaignName) LIKE '%all product%' THEN 'All Product'\n",
    "\t\t        WHEN lower(googleAdsCampaignName) LIKE '%all-product%' THEN 'All Product'\n",
    "\t\t        else 'Others'\n",
    "\t\t        END AS product,\n",
    "            count(case when (created_date <= '{1}')then 1 end) as count_train,\n",
    "            count(case when (created_date >= '{1}')then 1 end) as count_valid,\n",
    "            min(date_format(created_date,'%Y-%m-%d')) as min, max(date_format(created_date,'%Y-%m-%d')) as max\n",
    "        from digital_leads.google_ads_metrics\n",
    "        where date_format(created_date,'%Y-%m-%d') <= '{3}' and googleAdsCampaignName <> '(not set)'\n",
    "        group by googleAdsCampaignName, product\n",
    "        having  min(date_format(created_date,'%Y-%m-%d')) <= '{0}' \n",
    "                and max(date_format(created_date,'%Y-%m-%d')) > '{2}'\n",
    "                and count(case when (created_date <= '{1}')then 1 end) > 2\n",
    "                and count(case when (created_date >= '{1}')then 1 end) > 2\n",
    "    '''.format(days_ago_44,days_ago_30, days_ago_14,days_ago_1)\n",
    "    active = pd.read_sql(query,mydb)\n",
    "    mydb.close() #close the connection\n",
    "except Exception as e:\n",
    "    mydb.close()\n",
    "    print(str(e))\n",
    "active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Active_campaign = google.loc[google.campaign.isin(active.campaign.values)]\n",
    "               #, ['googleAdsCampaignName', 'created_date', 'advertiserAdClicks', 'cost']]\n",
    "Active_campaign['created_date'] = pd.to_datetime(Active_campaign['created_date']).dt.date\n",
    "#Active_campaign.campaign.unique()\n",
    "#Active_campaign.head()\n",
    "#Active_campaign.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_click = Active_campaign.loc[Active_campaign['created_date'] < days_ago_30, ['campaign', 'created_date', 'clicks']]\n",
    "valid_click = Active_campaign.loc[(Active_campaign['created_date'] >= days_ago_30) & (Active_campaign['created_date'] < days_ago_1), ['campaign', 'created_date', 'clicks']]\n",
    "train_cost = Active_campaign.loc[Active_campaign['created_date'] < days_ago_30, ['campaign', 'created_date', 'cost']]\n",
    "valid_cost = Active_campaign.loc[(Active_campaign['created_date'] >= days_ago_30) & (Active_campaign['created_date'] < days_ago_1), ['campaign', 'created_date', 'cost']]\n",
    "train_leads = Active_campaign.loc[Active_campaign['created_date'] < days_ago_30, ['campaign', 'created_date', 'leads']]\n",
    "valid_leads = Active_campaign.loc[(Active_campaign['created_date'] >= days_ago_30) & (Active_campaign['created_date'] < days_ago_1), ['campaign', 'created_date', 'leads']]\n",
    "train_prospect = Active_campaign.loc[Active_campaign['created_date'] < days_ago_30, ['campaign', 'created_date', 'prospect']]\n",
    "valid_prospect = Active_campaign.loc[(Active_campaign['created_date'] >= days_ago_30) & (Active_campaign['created_date'] < days_ago_1), ['campaign', 'created_date', 'prospect']]\n",
    "train_funding = Active_campaign.loc[Active_campaign['created_date'] < days_ago_30, ['campaign', 'created_date', 'funding']]\n",
    "valid_funding = Active_campaign.loc[(Active_campaign['created_date'] >= days_ago_30) & (Active_campaign['created_date'] < days_ago_1), ['campaign', 'created_date', 'funding']]\n",
    "train_NTF = Active_campaign.loc[Active_campaign['created_date'] < days_ago_30, ['campaign', 'created_date', 'NTF']]\n",
    "valid_NTF = Active_campaign.loc[(Active_campaign['created_date'] >= days_ago_30) & (Active_campaign['created_date'] < days_ago_1), ['campaign', 'created_date', 'NTF']]\n",
    "\n",
    "train_click = train_click.rename(columns={'created_date': 'ds', 'clicks': 'y', 'campaign': 'campaign'})\n",
    "valid_click = valid_click.rename(columns={'created_date': 'ds', 'clicks': 'y', 'campaign': 'campaign'})\n",
    "train_cost = train_cost.rename(columns={'created_date': 'ds', 'cost': 'y', 'campaign': 'campaign'})\n",
    "valid_cost = valid_cost.rename(columns={'created_date': 'ds', 'cost': 'y', 'campaign': 'campaign'})\n",
    "train_leads = train_leads.rename(columns={'created_date': 'ds', 'leads': 'y', 'campaign': 'campaign'})\n",
    "valid_leads = valid_click.rename(columns={'created_date': 'ds', 'leads': 'y', 'campaign': 'campaign'})\n",
    "train_prospect = train_prospect.rename(columns={'created_date': 'ds', 'prospect': 'y', 'campaign': 'campaign'})\n",
    "valid_prospect = valid_prospect.rename(columns={'created_date': 'ds', 'prospect': 'y', 'campaign': 'campaign'})\n",
    "train_funding = train_funding.rename(columns={'created_date': 'ds', 'funding': 'y', 'campaign': 'campaign'})\n",
    "valid_funding = valid_funding.rename(columns={'created_date': 'ds', 'funding': 'y', 'campaign': 'campaign'})\n",
    "train_NTF = train_NTF.rename(columns={'created_date': 'ds', 'NTF': 'y', 'campaign': 'campaign'})\n",
    "valid_NTF = valid_NTF.rename(columns={'created_date': 'ds', 'NTF': 'y', 'campaign': 'campaign'})\n",
    "\n",
    "train_click['ds']= pd.to_datetime(train_click['ds'])\n",
    "valid_click['ds']= pd.to_datetime(valid_click['ds'])\n",
    "train_cost['ds']= pd.to_datetime(train_cost['ds'])\n",
    "valid_cost['ds']= pd.to_datetime(valid_cost['ds'])\n",
    "train_leads['ds']= pd.to_datetime(train_leads['ds'])\n",
    "valid_leads['ds']= pd.to_datetime(valid_leads['ds'])\n",
    "train_prospect['ds']= pd.to_datetime(train_prospect['ds'])\n",
    "valid_prospect['ds']= pd.to_datetime(valid_prospect['ds'])\n",
    "train_funding['ds']= pd.to_datetime(train_funding['ds'])\n",
    "valid_funding['ds']= pd.to_datetime(valid_funding['ds'])\n",
    "train_NTF['ds']= pd.to_datetime(train_NTF['ds'])\n",
    "valid_NTF['ds']= pd.to_datetime(valid_NTF['ds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_click = train_click.loc[train_click['ds'].dt.date >= days_ago_60]\n",
    "hist_cost = train_cost.loc[train_cost['ds'].dt.date >= days_ago_60]\n",
    "hist_leads = train_leads.loc[train_leads['ds'].dt.date >= days_ago_60]\n",
    "hist_prospect = train_prospect.loc[train_prospect['ds'].dt.date >= days_ago_60]\n",
    "hist_funding = train_funding.loc[train_funding['ds'].dt.date >= days_ago_60]\n",
    "hist_NTF = train_NTF.loc[train_NTF['ds'].dt.date >= days_ago_60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"with exclusion as (SELECT campaign, sum(y) FROM train_click group by campaign having sum(y) is null\n",
    "       ) select * from train_click where campaign not in (SELECT campaign from exclusion);\"\"\"\n",
    "train_click = sqldf(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"with exclusion as (SELECT campaign, sum(y) FROM train_cost group by campaign having sum(y) is null\n",
    "       ) select * from train_cost where campaign not in (SELECT campaign from exclusion);\"\"\"\n",
    "train_cost = sqldf(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"with exclusion as (SELECT campaign, sum(y) FROM train_leads group by campaign having sum(y) is null\n",
    "       ) select * from train_leads where campaign not in (SELECT campaign from exclusion);\"\"\"\n",
    "train_leads = sqldf(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"with exclusion as (SELECT campaign, sum(y) FROM train_prospect group by campaign having sum(y) is null\n",
    "       ) select * from train_prospect where campaign not in (SELECT campaign from exclusion);\"\"\"\n",
    "train_prospect = sqldf(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"with exclusion as (SELECT campaign, sum(y) FROM train_funding group by campaign having sum(y) is null\n",
    "       ) select * from train_funding where campaign not in (SELECT campaign from exclusion);\"\"\"\n",
    "train_funding = sqldf(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"with exclusion as (SELECT campaign, sum(y) FROM train_NTF group by campaign having sum(y) is null\n",
    "       ) select * from train_NTF where campaign not in (SELECT campaign from exclusion);\"\"\"\n",
    "train_NTF = sqldf(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:25:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:25:03 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "campaign: Leads | BPKB Mobil | Search | Web 1 | Nationwide | Targeting | General\n",
      "campaign: Leads | Seritifikat Rumah | Discovery | Web 1 | Cover Area | All Time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:25:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:25:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:25:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:25:03 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "campaign: Leads | BPKB Mobil | Discovery | Web 1 | Nationwide | All Time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:25:04 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "campaign: Leads | BPKB Motor | Discovery | Web 1 | Nationwide\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:25:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:25:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:25:04 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "campaign: Leads | BPKB Motor | Search | Web 1 | Nationwide | All Time | New Audience\n",
      "campaign: Leads | BPKB Mobil | Search | Web 1 | Jabodetabek | New\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:25:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:25:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:25:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:25:04 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "campaign: Leads | BPKB Motor | Search | Web 1 | Jabarteng\n",
      "campaign: Leads | BPKB Motor | Search | Web 1 | Jabodetabek\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:25:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:25:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:25:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:25:05 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "campaign: Leads | Rumah | Search | Web 1 | Jabodetabek\n",
      "campaign: Leads | BPKB Mobil | Search | Web 1 | Jabarteng\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:25:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:25:05 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WAPE :  0.5827759269376561\n",
      "WBPE :  -0.2692994593624651\n",
      "WCPE :  0.6352439117592736\n"
     ]
    }
   ],
   "source": [
    "click = list()\n",
    "for campaign in train_click['campaign'].unique():\n",
    "    print('campaign:', campaign)\n",
    "    train_ = train_click.loc[train_click['campaign'] == campaign]\n",
    "    valid_ = valid_click.loc[valid_click['campaign'] == campaign]\n",
    "\n",
    "    m = Prophet(seasonality_mode='additive', yearly_seasonality=False, \n",
    "                weekly_seasonality=True, daily_seasonality=True\n",
    "               )\n",
    "    if train_.shape[0] > 2:\n",
    "        m.fit(train_)\n",
    "    \n",
    "    future = m.make_future_dataframe(periods=60, include_history=False)\n",
    "    future = future.merge(valid_[['ds']], on='ds', how='left')\n",
    "    forecast = m.predict(future)\n",
    "    forecast['campaign'] = campaign\n",
    "    click.append(forecast[['ds', 'yhat', 'campaign']])\n",
    "    \n",
    "click = pd.concat(click, ignore_index=True)\n",
    "click['yhat'] = click['yhat'].clip(lower=0)\n",
    "click = click.merge(valid_click, on=['ds', 'campaign'], how='left')\n",
    "print(\"WAPE : \" , wape(click['y'], click['yhat']))\n",
    "print(\"WBPE : \" , wbpe(click['y'], click['yhat']))\n",
    "print(\"WCPE : \" , wcpe(wape(click['y'], click['yhat']), wbpe(click['y'], click['yhat']),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:25:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:25:06 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "campaign: Leads | BPKB Mobil | Search | Web 1 | Nationwide | Targeting | General\n",
      "campaign: Leads | Seritifikat Rumah | Discovery | Web 1 | Cover Area | All Time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:25:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:25:07 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:25:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:25:07 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "campaign: Leads | BPKB Mobil | Discovery | Web 1 | Nationwide | All Time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:25:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:25:07 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "campaign: Leads | BPKB Motor | Discovery | Web 1 | Nationwide\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:25:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:25:07 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "campaign: Leads | BPKB Motor | Search | Web 1 | Nationwide | All Time | New Audience\n",
      "campaign: Leads | BPKB Mobil | Search | Web 1 | Jabodetabek | New\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:25:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:25:07 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:25:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:25:08 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "campaign: Leads | BPKB Motor | Search | Web 1 | Jabarteng\n",
      "campaign: Leads | BPKB Motor | Search | Web 1 | Jabodetabek\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:25:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:25:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:25:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:25:08 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "campaign: Leads | Rumah | Search | Web 1 | Jabodetabek\n",
      "campaign: Leads | BPKB Mobil | Search | Web 1 | Jabarteng\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:25:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:25:08 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WAPE :  0.6827424661968873\n",
      "WBPE :  -0.23023600582880752\n",
      "WCPE :  0.5989163468775912\n"
     ]
    }
   ],
   "source": [
    "cost = list()\n",
    "for campaign in train_cost['campaign'].unique():\n",
    "    print('campaign:', campaign)\n",
    "    train_ = train_cost.loc[train_cost['campaign'] == campaign]\n",
    "    valid_ = valid_cost.loc[valid_cost['campaign'] == campaign]\n",
    "    \n",
    "    m = Prophet(seasonality_mode='additive', yearly_seasonality=False, \n",
    "                weekly_seasonality=True, daily_seasonality=True\n",
    "               )\n",
    "    m.fit(train_)\n",
    "    \n",
    "    future = m.make_future_dataframe(periods=60, include_history=False)\n",
    "    future = future.merge(valid_[['ds']], on='ds', how='left')\n",
    "    forecast = m.predict(future)\n",
    "    forecast['campaign'] = campaign\n",
    "    cost.append(forecast[['ds', 'yhat', 'campaign']])\n",
    "    \n",
    "cost = pd.concat(cost, ignore_index=True)\n",
    "cost['yhat'] = cost['yhat'].clip(lower=0)\n",
    "cost = cost.merge(valid_cost, on=['ds', 'campaign'], how='left')\n",
    "print(\"WAPE : \" , wape(cost['y'], cost['yhat']))\n",
    "print(\"WBPE : \" , wbpe(cost['y'], cost['yhat']))\n",
    "print(\"WCPE : \" , wcpe(wape(cost['y'], cost['yhat']), wbpe(cost['y'], cost['yhat']),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:25:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:25:10 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "campaign: Leads | BPKB Mobil | Search | Web 1 | Nationwide | Targeting | General\n",
      "campaign: Leads | Seritifikat Rumah | Discovery | Web 1 | Cover Area | All Time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:25:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:25:10 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:25:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:25:10 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "campaign: Leads | BPKB Mobil | Discovery | Web 1 | Nationwide | All Time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:25:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:25:10 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "campaign: Leads | BPKB Motor | Discovery | Web 1 | Nationwide\n",
      "campaign: Leads | BPKB Motor | Search | Web 1 | Nationwide | All Time | New Audience\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:25:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:25:10 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:25:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:25:11 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "campaign: Leads | BPKB Motor | Search | Web 1 | Jabarteng\n",
      "campaign: Leads | BPKB Motor | Search | Web 1 | Jabodetabek\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:25:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:25:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:25:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:25:12 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "campaign: Leads | Rumah | Search | Web 1 | Jabodetabek\n",
      "campaign: Leads | BPKB Mobil | Search | Web 1 | Jabarteng\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:25:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:25:13 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WAPE :  0.9047264631632064\n",
      "WBPE :  0.8451731028880485\n",
      "WCPE :  0.1376220082961027\n"
     ]
    }
   ],
   "source": [
    "leads = list()\n",
    "for campaign in train_leads['campaign'].unique():\n",
    "    print('campaign:', campaign)\n",
    "    train_ = train_leads.loc[train_leads['campaign'] == campaign]\n",
    "    valid_ = valid_leads.loc[valid_leads['campaign'] == campaign]\n",
    "    \n",
    "    m = Prophet(seasonality_mode='additive', yearly_seasonality=False, \n",
    "                weekly_seasonality=True, daily_seasonality=True\n",
    "               )\n",
    "    m.fit(train_)\n",
    "    \n",
    "    future = m.make_future_dataframe(periods=60, include_history=False)\n",
    "    future = future.merge(valid_[['ds']], on='ds', how='left')\n",
    "    forecast = m.predict(future)\n",
    "    forecast['campaign'] = campaign\n",
    "    leads.append(forecast[['ds', 'yhat', 'campaign']])\n",
    "    \n",
    "leads = pd.concat(leads, ignore_index=True)\n",
    "leads['yhat'] = leads['yhat'].clip(lower=0)\n",
    "leads = leads.merge(valid_leads, on=['ds', 'campaign'], how='left')\n",
    "print(\"WAPE : \" , wape(leads['y'], leads['yhat']))\n",
    "print(\"WBPE : \" , wbpe(leads['y'], leads['yhat']))\n",
    "print(\"WCPE : \" , wcpe(wape(leads['y'], leads['yhat']), wbpe(leads['y'], leads['yhat']),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:25:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:25:13 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "campaign: Leads | BPKB Mobil | Search | Web 1 | Nationwide | Targeting | General\n",
      "campaign: Leads | Seritifikat Rumah | Discovery | Web 1 | Cover Area | All Time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:25:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:25:13 - cmdstanpy - INFO - Chain [1] done processing\n",
      "15:25:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:25:13 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "campaign: Leads | BPKB Mobil | Discovery | Web 1 | Nationwide | All Time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:25:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:25:13 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "campaign: Leads | BPKB Motor | Discovery | Web 1 | Nationwide\n",
      "campaign: Leads | BPKB Motor | Search | Web 1 | Nationwide | All Time | New Audience\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:25:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:25:14 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "campaign: Leads | BPKB Motor | Search | Web 1 | Jabodetabek\n",
      "campaign: Leads | Rumah | Search | Web 1 | Jabodetabek\n",
      "campaign: Leads | BPKB Mobil | Search | Web 1 | Jabarteng\n",
      "WAPE :  3.1531389044856035\n",
      "WBPE :  -2.5713207226674215\n",
      "WCPE :  nan\n"
     ]
    }
   ],
   "source": [
    "prospect = list()\n",
    "for campaign in train_prospect['campaign'].unique():\n",
    "    print('campaign:', campaign)\n",
    "    train_ = train_prospect.loc[train_prospect['campaign'] == campaign]\n",
    "    valid_ = valid_prospect.loc[valid_prospect['campaign'] == campaign]\n",
    "    \n",
    "    m = Prophet(seasonality_mode='additive', yearly_seasonality=False, \n",
    "                weekly_seasonality=True, daily_seasonality=True\n",
    "               )\n",
    "    m.fit(train_)\n",
    "    \n",
    "    future = m.make_future_dataframe(periods=60, include_history=False)\n",
    "    future = future.merge(valid_[['ds']], on='ds', how='left')\n",
    "    forecast = m.predict(future)\n",
    "    forecast['campaign'] = campaign\n",
    "    prospect.append(forecast[['ds', 'yhat', 'campaign']])\n",
    "    \n",
    "prospect = pd.concat(prospect, ignore_index=True)\n",
    "prospect['yhat'] = prospect['yhat'].clip(lower=0)\n",
    "prospect = prospect.merge(valid_prospect, on=['ds', 'campaign'], how='left')\n",
    "print(\"WAPE : \" , wape(prospect['y'], prospect['yhat']))\n",
    "print(\"WBPE : \" , wbpe(prospect['y'], prospect['yhat']))\n",
    "print(\"WCPE : \" , wcpe(wape(prospect['y'], prospect['yhat']), wbpe(prospect['y'], prospect['yhat']),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "campaign: Leads | BPKB Mobil | Search | Web 1 | Nationwide | Targeting | General\n",
      "campaign: Leads | Seritifikat Rumah | Discovery | Web 1 | Cover Area | All Time\n",
      "campaign: Leads | BPKB Mobil | Discovery | Web 1 | Nationwide | All Time\n",
      "WAPE :  0.0\n",
      "WBPE :  0.0\n",
      "WCPE :  1.0\n"
     ]
    }
   ],
   "source": [
    "funding = list()\n",
    "for campaign in train_funding['campaign'].unique():\n",
    "    print('campaign:', campaign)\n",
    "    train_ = train_funding.loc[train_funding['campaign'] == campaign]\n",
    "    valid_ = valid_funding.loc[valid_funding['campaign'] == campaign]\n",
    "    train_['y'] = train_.iloc[-2:, train_.columns.get_loc('y')].fillna(0)\n",
    "\n",
    "    m = Prophet(seasonality_mode='additive', yearly_seasonality=False, \n",
    "                weekly_seasonality=True, daily_seasonality=True\n",
    "               )\n",
    "    m.fit(train_)\n",
    "    \n",
    "    future = m.make_future_dataframe(periods=60, include_history=False)\n",
    "    future = future.merge(valid_[['ds']], on='ds', how='left')\n",
    "    forecast = m.predict(future)\n",
    "    forecast['campaign'] = campaign\n",
    "    funding.append(forecast[['ds', 'yhat', 'campaign']])\n",
    "    \n",
    "funding = pd.concat(funding, ignore_index=True)\n",
    "funding['yhat'] = funding['yhat'].clip(lower=0)\n",
    "funding = funding.merge(valid_funding, on=['ds', 'campaign'], how='left')\n",
    "print(\"WAPE : \" , wape(funding['y'], funding['yhat']))\n",
    "print(\"WBPE : \" , wbpe(funding['y'], funding['yhat']))\n",
    "print(\"WCPE : \" , wcpe(wape(funding['y'], funding['yhat']), wbpe(funding['y'], funding['yhat']),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "campaign: Leads | BPKB Mobil | Search | Web 1 | Nationwide | Targeting | General\n",
      "campaign: Leads | Seritifikat Rumah | Discovery | Web 1 | Cover Area | All Time\n",
      "campaign: Leads | BPKB Mobil | Discovery | Web 1 | Nationwide | All Time\n",
      "WAPE :  0.0\n",
      "WBPE :  0.0\n",
      "WCPE :  1.0\n"
     ]
    }
   ],
   "source": [
    "NTF = list()\n",
    "for campaign in train_NTF['campaign'].unique():\n",
    "    print('campaign:', campaign)\n",
    "    train_ = train_NTF.loc[train_NTF['campaign'] == campaign]\n",
    "    valid_ = valid_NTF.loc[valid_NTF['campaign'] == campaign]\n",
    "    train_['y'] = train_.iloc[-2:, train_.columns.get_loc('y')].fillna(0)\n",
    "    \n",
    "    m = Prophet(seasonality_mode='additive', yearly_seasonality=False, \n",
    "                weekly_seasonality=True, daily_seasonality=True\n",
    "               )\n",
    "    m.fit(train_)\n",
    "    \n",
    "    future = m.make_future_dataframe(periods=60, include_history=False)\n",
    "    future = future.merge(valid_[['ds']], on='ds', how='left')\n",
    "    forecast = m.predict(future)\n",
    "    forecast['campaign'] = campaign\n",
    "    NTF.append(forecast[['ds', 'yhat', 'campaign']])\n",
    "    \n",
    "NTF = pd.concat(NTF, ignore_index=True)\n",
    "NTF['yhat'] = NTF['yhat'].clip(lower=0)\n",
    "NTF = NTF.merge(valid_NTF, on=['ds', 'campaign'], how='left')\n",
    "print(\"WAPE : \" , wape(NTF['y'], NTF['yhat']))\n",
    "print(\"WBPE : \" , wbpe(NTF['y'], NTF['yhat']))\n",
    "print(\"WCPE : \" , wcpe(wape(NTF['y'], NTF['yhat']), wbpe(NTF['y'], NTF['yhat']),2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_click = pd.concat([hist_click, click], ignore_index=True)\n",
    "result_cost = pd.concat([hist_cost, cost], ignore_index=True)\n",
    "result_leads = pd.concat([hist_leads, leads], ignore_index=True)\n",
    "result_prospect = pd.concat([hist_prospect, prospect], ignore_index=True)\n",
    "result_funding = pd.concat([hist_funding, funding], ignore_index=True)\n",
    "result_NTF = pd.concat([hist_NTF, NTF], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "campaign: Leads | BPKB Mobil | Search | Web 1 | Jabodetabek | New\n",
      "campaign: Leads | BPKB Mobil | Search | Web 1 | Nationwide | Targeting | General\n",
      "campaign: Leads | BPKB Motor | Search | Web 1 | Jabarteng\n",
      "campaign: Leads | BPKB Motor | Search | Web 1 | Jabodetabek\n",
      "campaign: Leads | Rumah | Search | Web 1 | Jabodetabek\n",
      "campaign: Leads | BPKB Mobil | Search | Web 1 | Jabarteng\n",
      "campaign: Leads | BPKB Motor | Search | Web 1 | Nationwide | All Time | New Audience\n",
      "campaign: Leads | Seritifikat Rumah | Discovery | Web 1 | Cover Area | All Time\n",
      "campaign: Leads | BPKB Mobil | Discovery | Web 1 | Nationwide | All Time\n",
      "campaign: Leads | BPKB Motor | Discovery | Web 1 | Nationwide\n",
      "WAPE :  0.1877652955864517\n",
      "WBPE :  0.18357295120025868\n",
      "WCPE :  0.8155851212913183\n"
     ]
    }
   ],
   "source": [
    "Click_SMA = []\n",
    "ma_window=14\n",
    "\n",
    "y_hat_sma = result_click[['ds','campaign']]\n",
    "train_click['ds']= pd.to_datetime(train_click['ds'])\n",
    "y_hat_sma = pd.merge(y_hat_sma,\n",
    "                 train_click,\n",
    "                 left_on=['ds','campaign'], right_on = ['ds','campaign'], \n",
    "                 how='left')\n",
    "\n",
    "for campaign in y_hat_sma['campaign'].unique():\n",
    "    print('campaign:', campaign)\n",
    "    train_ = y_hat_sma.loc[y_hat_sma['campaign'] == campaign].reset_index(drop=True)\n",
    "    \n",
    "    train_len = len(hist_click.loc[hist_click['campaign'] == campaign])\n",
    "    valid_ = valid_click.loc[valid_click['campaign'] == campaign]\n",
    "    #print(train_len)\n",
    "    \n",
    "    for x in range(59): #\n",
    "        train_['sma_forecast'] = train_['y'].rolling(ma_window).mean()\n",
    "        train_[\"lag1_sma_forecast\"] = (train_.groupby([\"campaign\"])[\"sma_forecast\"].shift())\n",
    "        train_.y[train_len:train_len+x+1] = train_.lag1_sma_forecast[train_len:train_len+x+1]\n",
    "    #print(train_.tail(55))\n",
    "    \n",
    "    Click_SMA.append(train_[['ds', 'lag1_sma_forecast', 'campaign']])\n",
    "    \n",
    "Click_SMA_df = pd.concat(Click_SMA, ignore_index=True)\n",
    "Click_SMA_df = Click_SMA_df.merge(valid_click, on=['ds', 'campaign'], how='left')\n",
    "print(\"WAPE : \" , wape(Click_SMA_df['y'], Click_SMA_df['lag1_sma_forecast']))\n",
    "print(\"WBPE : \" , wbpe(Click_SMA_df['y'], Click_SMA_df['lag1_sma_forecast']))\n",
    "print(\"WCPE : \" , wcpe(wape(Click_SMA_df['y'], Click_SMA_df['lag1_sma_forecast']), wbpe(Click_SMA_df['y'], Click_SMA_df['lag1_sma_forecast']),2))\n",
    "\n",
    "result_click = result_click.merge(Click_SMA_df[['ds','campaign','lag1_sma_forecast']], on=['ds', 'campaign'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "campaign: Leads | BPKB Mobil | Search | Web 1 | Jabodetabek | New\n",
      "campaign: Leads | BPKB Mobil | Search | Web 1 | Nationwide | Targeting | General\n",
      "campaign: Leads | BPKB Motor | Search | Web 1 | Jabarteng\n",
      "campaign: Leads | BPKB Motor | Search | Web 1 | Jabodetabek\n",
      "campaign: Leads | Rumah | Search | Web 1 | Jabodetabek\n",
      "campaign: Leads | BPKB Mobil | Search | Web 1 | Jabarteng\n",
      "campaign: Leads | BPKB Motor | Search | Web 1 | Nationwide | All Time | New Audience\n",
      "campaign: Leads | Seritifikat Rumah | Discovery | Web 1 | Cover Area | All Time\n",
      "campaign: Leads | BPKB Mobil | Discovery | Web 1 | Nationwide | All Time\n",
      "campaign: Leads | BPKB Motor | Discovery | Web 1 | Nationwide\n",
      "WAPE :  0.29401658276970843\n",
      "WBPE :  0.28770177757947973\n",
      "WCPE :  0.7110262400816513\n"
     ]
    }
   ],
   "source": [
    "Cost_SMA = []\n",
    "ma_window=14\n",
    "\n",
    "y_hat_sma = result_cost[['ds','campaign']]\n",
    "train_cost['ds']= pd.to_datetime(train_cost['ds'])\n",
    "y_hat_sma = pd.merge(y_hat_sma,\n",
    "                 train_cost,\n",
    "                 left_on=['ds','campaign'], right_on = ['ds','campaign'], \n",
    "                 how='left')\n",
    "\n",
    "for campaign in y_hat_sma['campaign'].unique():\n",
    "    print('campaign:', campaign)\n",
    "    train_ = y_hat_sma.loc[y_hat_sma['campaign'] == campaign].reset_index(drop=True)\n",
    "    \n",
    "    train_len = len(hist_cost.loc[hist_cost['campaign'] == campaign])\n",
    "    valid_ = valid_cost.loc[valid_cost['campaign'] == campaign]\n",
    "    #print(train_len)\n",
    "    \n",
    "    for x in range(59): #\n",
    "        train_['sma_forecast'] = train_['y'].rolling(ma_window).mean()\n",
    "        train_[\"lag1_sma_forecast\"] = (train_.groupby([\"campaign\"])[\"sma_forecast\"].shift())\n",
    "        train_.y[train_len:train_len+x+1] = train_.lag1_sma_forecast[train_len:train_len+x+1]\n",
    "    #print(train_.tail(55))\n",
    "    \n",
    "    Cost_SMA.append(train_[['ds', 'lag1_sma_forecast', 'campaign']])\n",
    "    \n",
    "Cost_SMA_df = pd.concat(Cost_SMA, ignore_index=True)\n",
    "Cost_SMA_df = Cost_SMA_df.merge(valid_cost, on=['ds', 'campaign'], how='left')\n",
    "print(\"WAPE : \" , wape(Cost_SMA_df['y'], Cost_SMA_df['lag1_sma_forecast']))\n",
    "print(\"WBPE : \" , wbpe(Cost_SMA_df['y'], Cost_SMA_df['lag1_sma_forecast']))\n",
    "print(\"WCPE : \" , wcpe(wape(Cost_SMA_df['y'], Cost_SMA_df['lag1_sma_forecast']), wbpe(Cost_SMA_df['y'], Cost_SMA_df['lag1_sma_forecast']),2))\n",
    "\n",
    "result_cost = result_cost.merge(Cost_SMA_df[['ds','campaign','lag1_sma_forecast']], on=['ds', 'campaign'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "campaign: Leads | BPKB Mobil | Search | Web 1 | Jabodetabek | New\n",
      "campaign: Leads | BPKB Mobil | Search | Web 1 | Nationwide | Targeting | General\n",
      "campaign: Leads | BPKB Motor | Search | Web 1 | Jabarteng\n",
      "campaign: Leads | BPKB Motor | Search | Web 1 | Jabodetabek\n",
      "campaign: Leads | Rumah | Search | Web 1 | Jabodetabek\n",
      "campaign: Leads | BPKB Mobil | Search | Web 1 | Jabarteng\n",
      "campaign: Leads | BPKB Motor | Search | Web 1 | Nationwide | All Time | New Audience\n",
      "campaign: Leads | Seritifikat Rumah | Discovery | Web 1 | Cover Area | All Time\n",
      "campaign: Leads | BPKB Mobil | Discovery | Web 1 | Nationwide | All Time\n",
      "campaign: Leads | BPKB Motor | Discovery | Web 1 | Nationwide\n",
      "WAPE :  0.0\n",
      "WBPE :  0.0\n",
      "WCPE :  1.0\n"
     ]
    }
   ],
   "source": [
    "Leads_SMA = []\n",
    "ma_window=14\n",
    "\n",
    "y_hat_sma = result_leads[['ds','campaign']]\n",
    "train_leads['ds']= pd.to_datetime(train_leads['ds'])\n",
    "y_hat_sma = pd.merge(y_hat_sma,\n",
    "                 train_leads,\n",
    "                 left_on=['ds','campaign'], right_on = ['ds','campaign'], \n",
    "                 how='left')\n",
    "\n",
    "for campaign in y_hat_sma['campaign'].unique():\n",
    "    print('campaign:', campaign)\n",
    "    train_ = y_hat_sma.loc[y_hat_sma['campaign'] == campaign].reset_index(drop=True)\n",
    "    \n",
    "    train_len = len(hist_leads.loc[hist_leads['campaign'] == campaign])\n",
    "    valid_ = valid_leads.loc[valid_leads['campaign'] == campaign]\n",
    "    #print(train_len)\n",
    "    \n",
    "    for x in range(59): #\n",
    "        train_['sma_forecast'] = train_['y'].rolling(ma_window).mean()\n",
    "        train_[\"lag1_sma_forecast\"] = (train_.groupby([\"campaign\"])[\"sma_forecast\"].shift())\n",
    "        train_.y[train_len:train_len+x+1] = train_.lag1_sma_forecast[train_len:train_len+x+1]\n",
    "    #print(train_.tail(55))\n",
    "    \n",
    "    Leads_SMA.append(train_[['ds', 'lag1_sma_forecast', 'campaign']])\n",
    "    \n",
    "Leads_SMA_df = pd.concat(Leads_SMA, ignore_index=True)\n",
    "Leads_SMA_df = Leads_SMA_df.merge(valid_leads, on=['ds', 'campaign'], how='left')\n",
    "print(\"WAPE : \" , wape(Leads_SMA_df['y'], Leads_SMA_df['lag1_sma_forecast']))\n",
    "print(\"WBPE : \" , wbpe(Leads_SMA_df['y'], Leads_SMA_df['lag1_sma_forecast']))\n",
    "print(\"WCPE : \" , wcpe(wape(Leads_SMA_df['y'], Leads_SMA_df['lag1_sma_forecast']), wbpe(Leads_SMA_df['y'], Leads_SMA_df['lag1_sma_forecast']),2))\n",
    "\n",
    "result_leads = result_leads.merge(Leads_SMA_df[['ds','campaign','lag1_sma_forecast']], on=['ds', 'campaign'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "campaign: Leads | BPKB Mobil | Search | Web 1 | Jabodetabek | New\n",
      "campaign: Leads | BPKB Mobil | Search | Web 1 | Nationwide | Targeting | General\n",
      "campaign: Leads | BPKB Motor | Search | Web 1 | Jabarteng\n",
      "campaign: Leads | BPKB Motor | Search | Web 1 | Jabodetabek\n",
      "campaign: Leads | Rumah | Search | Web 1 | Jabodetabek\n",
      "campaign: Leads | BPKB Mobil | Search | Web 1 | Jabarteng\n",
      "campaign: Leads | BPKB Motor | Search | Web 1 | Nationwide | All Time | New Audience\n",
      "campaign: Leads | Seritifikat Rumah | Discovery | Web 1 | Cover Area | All Time\n",
      "campaign: Leads | BPKB Mobil | Discovery | Web 1 | Nationwide | All Time\n",
      "campaign: Leads | BPKB Motor | Discovery | Web 1 | Nationwide\n",
      "WAPE :  0.0\n",
      "WBPE :  0.0\n",
      "WCPE :  1.0\n"
     ]
    }
   ],
   "source": [
    "Prospect_SMA = []\n",
    "ma_window=14\n",
    "\n",
    "y_hat_sma = result_prospect[['ds','campaign']]\n",
    "train_prospect['ds']= pd.to_datetime(train_prospect['ds'])\n",
    "y_hat_sma = pd.merge(y_hat_sma,\n",
    "                 train_prospect,\n",
    "                 left_on=['ds','campaign'], right_on = ['ds','campaign'], \n",
    "                 how='left')\n",
    "\n",
    "for campaign in y_hat_sma['campaign'].unique():\n",
    "    print('campaign:', campaign)\n",
    "    train_ = y_hat_sma.loc[y_hat_sma['campaign'] == campaign].reset_index(drop=True)\n",
    "    \n",
    "    train_len = len(hist_prospect.loc[hist_prospect['campaign'] == campaign])\n",
    "    valid_ = valid_prospect.loc[valid_prospect['campaign'] == campaign]\n",
    "    #print(train_len)\n",
    "    \n",
    "    for x in range(59): #\n",
    "        train_['sma_forecast'] = train_['y'].rolling(ma_window).mean()\n",
    "        train_[\"lag1_sma_forecast\"] = (train_.groupby([\"campaign\"])[\"sma_forecast\"].shift())\n",
    "        train_.y[train_len:train_len+x+1] = train_.lag1_sma_forecast[train_len:train_len+x+1]\n",
    "    #print(train_.tail(55))\n",
    "    \n",
    "    Prospect_SMA.append(train_[['ds', 'lag1_sma_forecast', 'campaign']])\n",
    "    \n",
    "Prospect_SMA_df = pd.concat(Prospect_SMA, ignore_index=True)\n",
    "Prospect_SMA_df = Prospect_SMA_df.merge(valid_prospect, on=['ds', 'campaign'], how='left')\n",
    "print(\"WAPE : \" , wape(Prospect_SMA_df['y'], Prospect_SMA_df['lag1_sma_forecast']))\n",
    "print(\"WBPE : \" , wbpe(Prospect_SMA_df['y'], Prospect_SMA_df['lag1_sma_forecast']))\n",
    "print(\"WCPE : \" , wcpe(wape(Prospect_SMA_df['y'], Prospect_SMA_df['lag1_sma_forecast']), wbpe(Prospect_SMA_df['y'], Prospect_SMA_df['lag1_sma_forecast']),2))\n",
    "\n",
    "result_prospect = result_prospect.merge(Prospect_SMA_df[['ds','campaign','lag1_sma_forecast']], on=['ds', 'campaign'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "campaign: Leads | BPKB Mobil | Search | Web 1 | Jabodetabek | New\n",
      "campaign: Leads | BPKB Mobil | Search | Web 1 | Nationwide | Targeting | General\n",
      "campaign: Leads | BPKB Motor | Search | Web 1 | Jabarteng\n",
      "campaign: Leads | BPKB Motor | Search | Web 1 | Jabodetabek\n",
      "campaign: Leads | Rumah | Search | Web 1 | Jabodetabek\n",
      "campaign: Leads | BPKB Mobil | Search | Web 1 | Jabarteng\n",
      "campaign: Leads | BPKB Motor | Search | Web 1 | Nationwide | All Time | New Audience\n",
      "campaign: Leads | Seritifikat Rumah | Discovery | Web 1 | Cover Area | All Time\n",
      "campaign: Leads | BPKB Mobil | Discovery | Web 1 | Nationwide | All Time\n",
      "WAPE :  0.0\n",
      "WBPE :  0.0\n",
      "WCPE :  1.0\n"
     ]
    }
   ],
   "source": [
    "Funding_SMA = []\n",
    "ma_window=14\n",
    "\n",
    "y_hat_sma = result_funding[['ds','campaign']]\n",
    "train_funding['ds']= pd.to_datetime(train_funding['ds'])\n",
    "y_hat_sma = pd.merge(y_hat_sma,\n",
    "                 train_funding,\n",
    "                 left_on=['ds','campaign'], right_on = ['ds','campaign'], \n",
    "                 how='left')\n",
    "\n",
    "for campaign in y_hat_sma['campaign'].unique():\n",
    "    print('campaign:', campaign)\n",
    "    train_ = y_hat_sma.loc[y_hat_sma['campaign'] == campaign].reset_index(drop=True)\n",
    "    \n",
    "    train_len = len(hist_funding.loc[hist_funding['campaign'] == campaign])\n",
    "    valid_ = valid_funding.loc[valid_funding['campaign'] == campaign]\n",
    "    #print(train_len)\n",
    "    \n",
    "    for x in range(59): #\n",
    "        train_['sma_forecast'] = train_['y'].rolling(ma_window).mean()\n",
    "        train_[\"lag1_sma_forecast\"] = (train_.groupby([\"campaign\"])[\"sma_forecast\"].shift())\n",
    "        train_.y[train_len:train_len+x+1] = train_.lag1_sma_forecast[train_len:train_len+x+1]\n",
    "    #print(train_.tail(55))\n",
    "    \n",
    "    Funding_SMA.append(train_[['ds', 'lag1_sma_forecast', 'campaign']])\n",
    "    \n",
    "Funding_SMA_df = pd.concat(Funding_SMA, ignore_index=True)\n",
    "Funding_SMA_df = Funding_SMA_df.merge(valid_funding, on=['ds', 'campaign'], how='left')\n",
    "print(\"WAPE : \" , wape(Funding_SMA_df['y'], Funding_SMA_df['lag1_sma_forecast']))\n",
    "print(\"WBPE : \" , wbpe(Funding_SMA_df['y'], Funding_SMA_df['lag1_sma_forecast']))\n",
    "print(\"WCPE : \" , wcpe(wape(Funding_SMA_df['y'], Funding_SMA_df['lag1_sma_forecast']), wbpe(Funding_SMA_df['y'], Funding_SMA_df['lag1_sma_forecast']),2))\n",
    "\n",
    "result_funding = result_funding.merge(Funding_SMA_df[['ds','campaign','lag1_sma_forecast']], on=['ds', 'campaign'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "campaign: Leads | BPKB Mobil | Search | Web 1 | Jabodetabek | New\n",
      "campaign: Leads | BPKB Mobil | Search | Web 1 | Nationwide | Targeting | General\n",
      "campaign: Leads | BPKB Motor | Search | Web 1 | Jabarteng\n",
      "campaign: Leads | BPKB Motor | Search | Web 1 | Jabodetabek\n",
      "campaign: Leads | Rumah | Search | Web 1 | Jabodetabek\n",
      "campaign: Leads | BPKB Mobil | Search | Web 1 | Jabarteng\n",
      "campaign: Leads | BPKB Motor | Search | Web 1 | Nationwide | All Time | New Audience\n",
      "campaign: Leads | Seritifikat Rumah | Discovery | Web 1 | Cover Area | All Time\n",
      "campaign: Leads | BPKB Mobil | Discovery | Web 1 | Nationwide | All Time\n",
      "WAPE :  0.0\n",
      "WBPE :  0.0\n",
      "WCPE :  1.0\n"
     ]
    }
   ],
   "source": [
    "NTF_SMA = []\n",
    "ma_window=14\n",
    "\n",
    "y_hat_sma = result_NTF[['ds','campaign']]\n",
    "train_NTF['ds']= pd.to_datetime(train_NTF['ds'])\n",
    "y_hat_sma = pd.merge(y_hat_sma,\n",
    "                 train_NTF,\n",
    "                 left_on=['ds','campaign'], right_on = ['ds','campaign'], \n",
    "                 how='left')\n",
    "\n",
    "for campaign in y_hat_sma['campaign'].unique():\n",
    "    print('campaign:', campaign)\n",
    "    train_ = y_hat_sma.loc[y_hat_sma['campaign'] == campaign].reset_index(drop=True)\n",
    "    \n",
    "    train_len = len(hist_NTF.loc[hist_NTF['campaign'] == campaign])\n",
    "    valid_ = valid_NTF.loc[valid_NTF['campaign'] == campaign]\n",
    "    #print(train_len)\n",
    "    \n",
    "    for x in range(59): #\n",
    "        train_['sma_forecast'] = train_['y'].rolling(ma_window).mean()\n",
    "        train_[\"lag1_sma_forecast\"] = (train_.groupby([\"campaign\"])[\"sma_forecast\"].shift())\n",
    "        train_.y[train_len:train_len+x+1] = train_.lag1_sma_forecast[train_len:train_len+x+1]\n",
    "    #print(train_.tail(55))\n",
    "    \n",
    "    NTF_SMA.append(train_[['ds', 'lag1_sma_forecast', 'campaign']])\n",
    "    \n",
    "NTF_SMA_df = pd.concat(NTF_SMA, ignore_index=True)\n",
    "NTF_SMA_df = NTF_SMA_df.merge(valid_NTF, on=['ds', 'campaign'], how='left')\n",
    "print(\"WAPE : \" , wape(NTF_SMA_df['y'], NTF_SMA_df['lag1_sma_forecast']))\n",
    "print(\"WBPE : \" , wbpe(NTF_SMA_df['y'], NTF_SMA_df['lag1_sma_forecast']))\n",
    "print(\"WCPE : \" , wcpe(wape(NTF_SMA_df['y'], NTF_SMA_df['lag1_sma_forecast']), wbpe(NTF_SMA_df['y'], NTF_SMA_df['lag1_sma_forecast']),2))\n",
    "\n",
    "result_NTF = result_NTF.merge(NTF_SMA_df[['ds','campaign','lag1_sma_forecast']], on=['ds', 'campaign'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>product</th>\n",
       "      <th>metrics</th>\n",
       "      <th>campaign</th>\n",
       "      <th>ad_name</th>\n",
       "      <th>adset_name</th>\n",
       "      <th>date</th>\n",
       "      <th>actual</th>\n",
       "      <th>forecast</th>\n",
       "      <th>baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google</td>\n",
       "      <td>BPKB Mobil</td>\n",
       "      <td>Click</td>\n",
       "      <td>Leads | BPKB Mobil | Search | Web 1 | Jabodeta...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2023-06-05</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Google</td>\n",
       "      <td>BPKB Mobil</td>\n",
       "      <td>Click</td>\n",
       "      <td>Leads | BPKB Mobil | Search | Web 1 | Nationwi...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2023-06-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Google</td>\n",
       "      <td>BPKB Motor</td>\n",
       "      <td>Click</td>\n",
       "      <td>Leads | BPKB Motor | Search | Web 1 | Jabarteng</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2023-06-05</td>\n",
       "      <td>154.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Google</td>\n",
       "      <td>BPKB Motor</td>\n",
       "      <td>Click</td>\n",
       "      <td>Leads | BPKB Motor | Search | Web 1 | Jabodetabek</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2023-06-05</td>\n",
       "      <td>88.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Google</td>\n",
       "      <td>Sertifikat Rumah</td>\n",
       "      <td>Click</td>\n",
       "      <td>Leads | Rumah | Search | Web 1 | Jabodetabek</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2023-06-05</td>\n",
       "      <td>189.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source           product metrics  \\\n",
       "0  Google        BPKB Mobil   Click   \n",
       "1  Google        BPKB Mobil   Click   \n",
       "2  Google        BPKB Motor   Click   \n",
       "3  Google        BPKB Motor   Click   \n",
       "4  Google  Sertifikat Rumah   Click   \n",
       "\n",
       "                                            campaign ad_name adset_name  \\\n",
       "0  Leads | BPKB Mobil | Search | Web 1 | Jabodeta...                      \n",
       "1  Leads | BPKB Mobil | Search | Web 1 | Nationwi...                      \n",
       "2    Leads | BPKB Motor | Search | Web 1 | Jabarteng                      \n",
       "3  Leads | BPKB Motor | Search | Web 1 | Jabodetabek                      \n",
       "4       Leads | Rumah | Search | Web 1 | Jabodetabek                      \n",
       "\n",
       "        date  actual  forecast  baseline  \n",
       "0 2023-06-05    36.0       NaN       NaN  \n",
       "1 2023-06-05     NaN       NaN       NaN  \n",
       "2 2023-06-05   154.0       NaN       NaN  \n",
       "3 2023-06-05    88.0       NaN       NaN  \n",
       "4 2023-06-05   189.0       NaN       NaN  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_click['metrics'] = 'Click'\n",
    "result_cost['metrics'] = 'Cost'\n",
    "result_leads['metrics'] = 'Leads'\n",
    "result_prospect['metrics'] = 'Prospect'\n",
    "result_funding['metrics'] = 'Funding'\n",
    "result_NTF['metrics'] = 'NTF'\n",
    "forecast_list = [result_click, result_cost, result_leads, result_prospect, result_funding, result_NTF]\n",
    "forecast_google = pd.concat(forecast_list)\n",
    "forecast_google['source'] = 'Google'\n",
    "forecast_google['ad_name'] = ''\n",
    "forecast_google['adset_name'] = ''\n",
    "forecast_google = forecast_google.merge(active[['campaign','product']], on=['campaign'], how='left')\n",
    "forecast_google.rename(columns = {'ds':'date', 'y':'actual','yhat':'forecast','lag1_sma_forecast':'baseline'}, inplace = True)\n",
    "forecast_google = forecast_google.reindex(['source','product','metrics','campaign','ad_name','adset_name','date','actual','forecast','baseline'], axis=1)\n",
    "forecast_google.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forecast_google.to_csv('forecast_google.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
